{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Image Classification using CNNs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The problem we are gonna tackle is [The German Traffic Sign Recognition Benchmark(GTSRB)](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news). The problem is to to recognize the traffic sign from the images. Solving this problem is essential for self-driving cars to operate on roads.\n",
    "\n",
    "The dataset features 43 different signs under various sizes, lighting conditions, occlusions and is very similar to real-life data. Training set includes about 39000 images while test set has around 12000 images. Images are not guaranteed to be of fixed dimensions and the sign is not necessarily centered in each image. Each image contains about 10% border around the actual traffic sign.\n",
    "\n",
    "Our approach to solving the problem will of course be very successful convolutional neural networks (CNNs). CNNs are multi-layered feed-forward neural networks that are able to learn task-specific invariant features in a hierarchical manner.\n",
    "\n",
    "## A Brief Summary of the process\n",
    "\n",
    "Pre-Process Data — Although deep neural networks don’t require data pre-processing and CNNs learn these techniques themselves during model training, pre-processing can really accelerate the training process. We will be using a variety of pre-processing such as Mean, Centering, Normalizing, Histogram Equalizing Data.\n",
    "    \n",
    "Augment the dataset as per requirement(optional) — Deep neural networks simply perform better when there is more data. We will be using a variety of techniques such as rotation, scaling, translation, projective transformation, sobel edge , gaussian noise to increase the robustness and variety in our dataset.\n",
    "    \n",
    "Build a model — As mentioned before we will be using a convolutional neural network. The depth of convolutions, the number of layers, the type of activation functions will be chosen based on the problem at hand.\n",
    "    \n",
    "Search for best hyper-parameters — They are the knobs you get to turn such as learning rate, number of iterations, batch size , number of epochs, dropout rate , regularization factor etc. Choosing a subset of the entire problem and building a random search over a range of hyperparameters for finding the best possible combination is a good way of proceeding.\n",
    "\n",
    "Train the model using training dataset. Use the training loss as the optimization parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preprocessing\n",
    "Images vary a lot in illumination. They also vary in size. So, let’s write a function to do histogram equalization in HSV color space and resize the images to a standard size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All the training images are store into numpy arrays. We’ll also get labels of images from paths. We’ll convert targets to one-hot form as is required by keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images from X.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with  h5py.File('X.h5') as hf: \n",
    "        X, Y = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from X.h5\")\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")\n",
    "    root_dir = 'GTSRB/Final_Training/Images/'\n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))\n",
    "            label = get_class(img_path)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "\n",
    "    with h5py.File('X.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model\n",
    "1. We’ll use feed forward network with 6 convolutional layers followed by a fully connected hidden layer.\n",
    "2. We’ll also use dropout layers in between. Dropout regularizes the networks, i.e. it prevents the network from overfitting.\n",
    "3. All our layers have relu activations except the output layer.A rectified linear unit(relu) has output 0 if the input is less than 0, and raw output otherwise. That is, if the input is greater than 0, the output is equal to the input. \n",
    "4. Output layer uses softmax activation as it has to output the probability for each of the classes.A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 43 to be selected as the model’s output prediction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Configuration\n",
    "\n",
    "1. loss : Loss function we want to optimize. We cannot use error percentage as it is not continuous and thus non differentiable. We therefore use a proxy for it - categorical_crossentropy. \n",
    "2. optimizer : We use standard [stochastic gradient](http://cs231n.github.io/neural-networks-3/#sgd) descent with [Nesterov momentum](http://cs231n.github.io/neural-networks-3/#sgd).\n",
    "3. metric : Since we are dealing with a classification problem, our metric is accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/30\n",
      "31367/31367 [==============================] - 30s - loss: 1.1502 - acc: 0.6723 - val_loss: 0.1262 - val_acc: 0.9616\n",
      "Epoch 2/30\n",
      "31367/31367 [==============================] - 32s - loss: 0.2143 - acc: 0.9359 - val_loss: 0.0653 - val_acc: 0.9809\n",
      "Epoch 3/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.1342 - acc: 0.9604 - val_loss: 0.0590 - val_acc: 0.9825\n",
      "Epoch 4/30\n",
      "31367/31367 [==============================] - 35s - loss: 0.0967 - acc: 0.9715 - val_loss: 0.0778 - val_acc: 0.9756\n",
      "Epoch 5/30\n",
      "31367/31367 [==============================] - 35s - loss: 0.0832 - acc: 0.9755 - val_loss: 0.0358 - val_acc: 0.9887\n",
      "Epoch 6/30\n",
      "31367/31367 [==============================] - 22s - loss: 0.0695 - acc: 0.9783 - val_loss: 0.0367 - val_acc: 0.9894\n",
      "Epoch 7/30\n",
      "31367/31367 [==============================] - 23s - loss: 0.0636 - acc: 0.9800 - val_loss: 0.0323 - val_acc: 0.9922\n",
      "Epoch 8/30\n",
      "31367/31367 [==============================] - 23s - loss: 0.0559 - acc: 0.9830 - val_loss: 0.0247 - val_acc: 0.9929\n",
      "Epoch 9/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0496 - acc: 0.9850 - val_loss: 0.0241 - val_acc: 0.9938\n",
      "Epoch 10/30\n",
      "31367/31367 [==============================] - 28s - loss: 0.0436 - acc: 0.9870 - val_loss: 0.0319 - val_acc: 0.9916\n",
      "Epoch 11/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0249 - acc: 0.9923 - val_loss: 0.0197 - val_acc: 0.9957\n",
      "Epoch 12/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0193 - val_acc: 0.9958\n",
      "Epoch 13/30\n",
      "31367/31367 [==============================] - 32s - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0183 - val_acc: 0.9964\n",
      "Epoch 14/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0182 - val_acc: 0.9960\n",
      "Epoch 15/30\n",
      "31367/31367 [==============================] - 28s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0174 - val_acc: 0.9963\n",
      "Epoch 16/30\n",
      "31367/31367 [==============================] - 27s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0170 - val_acc: 0.9966\n",
      "Epoch 17/30\n",
      "31367/31367 [==============================] - 27s - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0159 - val_acc: 0.9971\n",
      "Epoch 18/30\n",
      "31367/31367 [==============================] - 23s - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 19/30\n",
      "31367/31367 [==============================] - 21s - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9971\n",
      "Epoch 20/30\n",
      "31367/31367 [==============================] - 25s - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0166 - val_acc: 0.9966\n",
      "Epoch 21/30\n",
      "31367/31367 [==============================] - 26s - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0164 - val_acc: 0.9967\n",
      "Epoch 22/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0060 - acc: 0.9979 - val_loss: 0.0163 - val_acc: 0.9966\n",
      "Epoch 23/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0164 - val_acc: 0.9967\n",
      "Epoch 24/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0166 - val_acc: 0.9967\n",
      "Epoch 25/30\n",
      "31367/31367 [==============================] - 27s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0165 - val_acc: 0.9968\n",
      "Epoch 26/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0164 - val_acc: 0.9969\n",
      "Epoch 27/30\n",
      "31367/31367 [==============================] - 27s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0165 - val_acc: 0.9968\n",
      "Epoch 28/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 29/30\n",
      "31367/31367 [==============================] - 24s - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0163 - val_acc: 0.9968\n",
      "Epoch 30/30\n",
      "31367/31367 [==============================] - 22s - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feaf3055898>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 30\n",
    "\n",
    "model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                    ModelCheckpoint('model.h5',save_best_only=True)]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training\n",
    "During training, the model will iterate over batches of training set, each of size *batch_size*. For each batch, gradients will be computed and updates will be made to the weights of the network automatically. One iteration over all the training set is referred to as an epoch. Training is usually run until the loss converges to a constant.\n",
    "\n",
    "We will add a couple of features to our training:\n",
    "\n",
    "1. Learning rate scheduler : Decaying learning rate over the epochs usually helps model learn better\n",
    "2. Model checkpoint : We will save the model with best validation accuracy. This is useful because our network might start overfitting after a certain number of epochs, but we want the best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "Load test data and evaluate the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('GT-final_test.csv',sep=';')\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    img_path = os.path.join('GTSRB/Final_Test/Images/',file_name)\n",
    "    X_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 2s     \n",
      "Test accuracy = 0.9792557403008709\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Augmentation\n",
    "If we can generate new images for training from the existing images, that will be a great way to increase the size of the dataset. This can be done by slightly\n",
    "\n",
    "1. Translating of image\n",
    "2. Rotating of image\n",
    "3. Shearing the image\n",
    "4. Zooming in/out of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reinstallise models \n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31367/31367 [==============================] - 27s - loss: 2.0311 - acc: 0.4023 - val_loss: 0.4975 - val_acc: 0.8258\n",
      "Epoch 2/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.7059 - acc: 0.7762 - val_loss: 0.2078 - val_acc: 0.9341\n",
      "Epoch 3/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.4047 - acc: 0.8763 - val_loss: 0.1255 - val_acc: 0.9621\n",
      "Epoch 4/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.2769 - acc: 0.9125 - val_loss: 0.0875 - val_acc: 0.9717\n",
      "Epoch 5/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.2266 - acc: 0.9308 - val_loss: 0.0459 - val_acc: 0.9865\n",
      "Epoch 6/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.1931 - acc: 0.9416 - val_loss: 0.0488 - val_acc: 0.9850\n",
      "Epoch 7/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.1737 - acc: 0.9477 - val_loss: 0.0383 - val_acc: 0.9881\n",
      "Epoch 8/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.1461 - acc: 0.9563 - val_loss: 0.0249 - val_acc: 0.9929\n",
      "Epoch 9/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.1406 - acc: 0.9591 - val_loss: 0.0257 - val_acc: 0.9926\n",
      "Epoch 10/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.1316 - acc: 0.9608 - val_loss: 0.0164 - val_acc: 0.9953\n",
      "Epoch 11/30\n",
      "31367/31367 [==============================] - 28s - loss: 0.0656 - acc: 0.9802 - val_loss: 0.0092 - val_acc: 0.9963\n",
      "Epoch 12/30\n",
      "31367/31367 [==============================] - 25s - loss: 0.0526 - acc: 0.9839 - val_loss: 0.0077 - val_acc: 0.9972\n",
      "Epoch 13/30\n",
      "31367/31367 [==============================] - 28s - loss: 0.0482 - acc: 0.9858 - val_loss: 0.0078 - val_acc: 0.9972\n",
      "Epoch 14/30\n",
      "31367/31367 [==============================] - 32s - loss: 0.0468 - acc: 0.9855 - val_loss: 0.0066 - val_acc: 0.9983\n",
      "Epoch 15/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.0446 - acc: 0.9864 - val_loss: 0.0059 - val_acc: 0.9982\n",
      "Epoch 16/30\n",
      "31367/31367 [==============================] - 32s - loss: 0.0394 - acc: 0.9879 - val_loss: 0.0058 - val_acc: 0.9985\n",
      "Epoch 17/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0414 - acc: 0.9877 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 18/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.0380 - acc: 0.9883 - val_loss: 0.0052 - val_acc: 0.9983\n",
      "Epoch 19/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.0354 - acc: 0.9894 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 20/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.0355 - acc: 0.9895 - val_loss: 0.0055 - val_acc: 0.9977\n",
      "Epoch 21/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.0357 - acc: 0.9895 - val_loss: 0.0050 - val_acc: 0.9981\n",
      "Epoch 22/30\n",
      "31367/31367 [==============================] - 32s - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0048 - val_acc: 0.9983\n",
      "Epoch 23/30\n",
      "31367/31367 [==============================] - 25s - loss: 0.0329 - acc: 0.9905 - val_loss: 0.0048 - val_acc: 0.9981\n",
      "Epoch 24/30\n",
      "31367/31367 [==============================] - 29s - loss: 0.0323 - acc: 0.9901 - val_loss: 0.0047 - val_acc: 0.9982\n",
      "Epoch 25/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0357 - acc: 0.9892 - val_loss: 0.0046 - val_acc: 0.9983\n",
      "Epoch 26/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0317 - acc: 0.9899 - val_loss: 0.0046 - val_acc: 0.9982\n",
      "Epoch 27/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0045 - val_acc: 0.9982\n",
      "Epoch 28/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0340 - acc: 0.9895 - val_loss: 0.0046 - val_acc: 0.9986\n",
      "Epoch 29/30\n",
      "31367/31367 [==============================] - 30s - loss: 0.0319 - acc: 0.9904 - val_loss: 0.0045 - val_acc: 0.9987\n",
      "Epoch 30/30\n",
      "31367/31367 [==============================] - 31s - loss: 0.0318 - acc: 0.9896 - val_loss: 0.0044 - val_acc: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea770a6630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 30\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0],\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint('model.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 3s     \n",
      "Test accuracy = 0.9828978622327791\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)    (None, 32, 48, 48)  896         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)    (None, 32, 46, 46)  9248        convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)      (None, 32, 23, 23)  0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)                (None, 32, 23, 23)  0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)    (None, 64, 23, 23)  18496       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D)   (None, 64, 21, 21)  36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)      (None, 64, 10, 10)  0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)                (None, 64, 10, 10)  0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D)   (None, 128, 10, 10) 73856       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D)   (None, 128, 8, 8)   147584      convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)      (None, 128, 4, 4)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)                (None, 128, 4, 4)   0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)                (None, 2048)        0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                    (None, 512)         1049088     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)                (None, 512)         0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                    (None, 43)          22059       dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1358155\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358155"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
